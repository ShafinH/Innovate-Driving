{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Beginner_StudentCopy_DriverDistractionSection2.ipynb","provenance":[{"file_id":"1YZgaJtO9Hfx-0CHPMtwFQDILIGtueD8U","timestamp":1592339830456}],"collapsed_sections":["uofnvxpz-qdI"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"aSeClkWgIORK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1592339945513,"user_tz":420,"elapsed":11346,"user":{"displayName":"Shafin Haque","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdwtEd_daS6_Iby03E8_oqJRD1DxQTM7iYf1dWzg=s64","userId":"00476594546562972086"}},"outputId":"5211c1de-4897-47b6-e1ae-ae7f13c35e0d"},"source":["import cv2\n","import numpy as np\n","\n","def label_to_numpy(labels):\n","  final_labels = np.zeros((len(labels), 4))\n","  for i in range(len(labels)):\n","    label = labels[i]\n","    if label == 'Attentive':\n","      final_labels[i,:] = np.array([1, 0, 0, 0])\n","    if label == 'DrinkingCoffee':\n","      final_labels[i,:] = np.array([0, 1, 0, 0])\n","    if label == 'UsingMirror':\n","      final_labels[i,:] = np.array([0, 0, 1, 0])\n","    if label == 'UsingRadio':\n","      final_labels[i,:] = np.array([0, 0, 0, 1])\n","  return final_labels\n","\n","def augment(data, augmenter):\n","  if len(data.shape) == 3:\n","    return augmenter.augment_image(data)\n","  if len(data.shape) == 4:\n","    return augmenter.augment_images(data)\n","    \n","def rotate(data, rotate):\n","  fun = augmenters.Affine(rotate = rotate)\n","  return augment(data, fun)\n","\n","def shear(data, shear):\n","  fun = augmenters.Affine(shear = shear)\n","  return augment(data, fun)\n","\n","def scale(data, scale):\n","  fun = augmenters.Affine(scale = shear)\n","  return augment(data, fun)\n","  \n","def flip_left_right(data):\n","  fun = augmenters.Fliplr()\n","  return augment(data, fun)\n","\n","def flip_up_down(data):\n","  fun = augmenters.Flipud()\n","  return augment(data, fun)\n","\n","def remove_color(data, channel):\n","  new_data = data.copy()\n","  if len(data.shape) == 3:\n","    new_data[:,:,channel] = 0\n","    return new_data\n","  if len(data.shape) == 4:\n","    new_data[:,:,:,channel] = 0\n","    return new_data\n","  \n","class pkg:\n","\n","  def get_metadata(metadata_path, which_splits = ['train', 'test']):  \n","\n","    metadata = pd.read_csv(metadata_path)\n","    keep_idx = metadata['split'].isin(which_splits)\n","    metadata = metadata[keep_idx]\n","    \n","    # Get dataframes for each class.\n","    df_coffee_train = metadata[(metadata['class'] == 'DrinkingCoffee') & \\\n","                         (metadata['split'] == 'train')]\n","    df_coffee_test = metadata[(metadata['class'] == 'DrinkingCoffee') & \\\n","                         (metadata['split'] == 'test')]\n","    df_mirror_train = metadata[(metadata['class'] == 'UsingMirror') & \\\n","                         (metadata['split'] == 'train')]\n","    df_mirror_test = metadata[(metadata['class'] == 'UsingMirror') & \\\n","                         (metadata['split'] == 'test')]\n","    df_attentive_train = metadata[(metadata['class'] == 'Attentive') & \\\n","                         (metadata['split'] == 'train')]\n","    df_attentive_test = metadata[(metadata['class'] == 'Attentive') & \\\n","                         (metadata['split'] == 'test')]\n","    df_radio_train = metadata[(metadata['class'] == 'UsingRadio') & \\\n","                         (metadata['split'] == 'train')]\n","    df_radio_test = metadata[(metadata['class'] == 'UsingRadio') & \\\n","                         (metadata['split'] == 'test')]\n","\n","    # Get number of items in class with lowest number of images.\n","    num_samples_train = min(df_coffee_train.shape[0], \\\n","                            df_mirror_train.shape[0], \\\n","                            df_attentive_train.shape[0], \\\n","                            df_radio_train.shape[0])\n","    num_samples_test = min(df_coffee_test.shape[0], \\\n","                            df_mirror_test.shape[0], \\\n","                            df_attentive_test.shape[0], \\\n","                            df_radio_test.shape[0])\n","\n","    # Resample each of the classes and concatenate the images.\n","    metadata_train = pd.concat([df_coffee_train.sample(num_samples_train), \\\n","                          df_mirror_train.sample(num_samples_train), \\\n","                          df_attentive_train.sample(num_samples_train), \\\n","                          df_radio_train.sample(num_samples_train) ])\n","    metadata_test = pd.concat([df_coffee_test.sample(num_samples_test), \\\n","                          df_mirror_test.sample(num_samples_test), \\\n","                          df_attentive_test.sample(num_samples_test), \\\n","                          df_radio_test.sample(num_samples_test) ])\n","    \n","    metadata = pd.concat( [metadata_train, metadata_test] )\n","    \n","    return metadata\n","\n","  def get_data_split(split_name, flatten, all_data, metadata, image_shape):\n","    '''\n","    returns images (data), labels from folder of format [image_folder]/[split_name]/[class_name]/\n","    flattens if flatten option is True \n","    '''\n","    # Get dataframes for each class.\n","    df_coffee_train = metadata[(metadata['class'] == 'DrinkingCoffee') & \\\n","                         (metadata['split'] == 'train')]\n","    df_coffee_test = metadata[(metadata['class'] == 'DrinkingCoffee') & \\\n","                         (metadata['split'] == 'test')]\n","    df_mirror_train = metadata[(metadata['class'] == 'UsingMirror') & \\\n","                         (metadata['split'] == 'train')]\n","    df_mirror_test = metadata[(metadata['class'] == 'UsingMirror') & \\\n","                         (metadata['split'] == 'test')]\n","    df_attentive_train = metadata[(metadata['class'] == 'Attentive') & \\\n","                         (metadata['split'] == 'train')]\n","    df_attentive_test = metadata[(metadata['class'] == 'Attentive') & \\\n","                         (metadata['split'] == 'test')]\n","    df_radio_train = metadata[(metadata['class'] == 'UsingRadio') & \\\n","                         (metadata['split'] == 'train')]\n","    df_radio_test = metadata[(metadata['class'] == 'UsingRadio') & \\\n","                         (metadata['split'] == 'test')]\n","\n","    # Get number of items in class with lowest number of images.\n","    num_samples_train = min(df_coffee_train.shape[0], \\\n","                            df_mirror_train.shape[0], \\\n","                            df_attentive_train.shape[0], \\\n","                            df_radio_train.shape[0])\n","    num_samples_test = min(df_coffee_test.shape[0], \\\n","                            df_mirror_test.shape[0], \\\n","                            df_attentive_test.shape[0], \\\n","                            df_radio_test.shape[0])\n","\n","    # Resample each of the classes and concatenate the images.\n","    metadata_train = pd.concat([df_coffee_train.sample(num_samples_train), \\\n","                          df_mirror_train.sample(num_samples_train), \\\n","                          df_attentive_train.sample(num_samples_train), \\\n","                          df_radio_train.sample(num_samples_train) ])\n","    metadata_test = pd.concat([df_coffee_test.sample(num_samples_test), \\\n","                          df_mirror_test.sample(num_samples_test), \\\n","                          df_attentive_test.sample(num_samples_test), \\\n","                          df_radio_test.sample(num_samples_test) ])\n","    \n","    metadata = pd.concat( [metadata_train, metadata_test] )\n","    \n","    sub_df = metadata[metadata['split'].isin([split_name])]\n","    index  = sub_df['index'].values\n","    labels = sub_df['class'].values\n","    data = all_data[index,:]\n","    if flatten:\n","      data = data.reshape([-1, np.product(image_shape)])\n","    return data, labels\n","\n","  def get_train_data(flatten, all_data, metadata, image_shape):\n","    return get_data_split('train', flatten, all_data, metadata, image_shape)\n","\n","  def get_test_data(flatten, all_data, metadata, image_shape):\n","    return get_data_split('test', flatten, all_data, metadata, image_shape)\n","\n","  def get_field_data(flatten, all_data, metadata, image_shape):\n","    return get_data_split('field', flatten, all_data, metadata, image_shape)\n","  \n","class helpers:\n","  #### PLOTTING\n","  def plot_image(data, num_ims, figsize=(8,6), labels = [], index = None, image_shape = [64,64,3]):\n","\n","    print(data.shape)\n","    num_dims   = len(data.shape)\n","    num_labels = len(labels)\n","\n","    # reshape data if necessary\n","    if num_dims == 1:\n","      data = data.reshape(target_shape)\n","    if num_dims == 2:\n","      data = data.reshape(-1,image_shape[0],image_shape[1],image_shape[2])\n","    num_dims   = len(data.shape)\n","\n","    if num_dims == 3:\n","      if num_labels > 1:\n","        print('Multiple labels does not make sense for single image.')\n","        return\n","\n","      label = labels      \n","      if num_labels == 0:\n","        label = ''\n","      image = data\n","\n","    if num_dims == 4:\n","      image = data[index, :]\n","      label = labels[index]\n","\n","    \n","    nrows=int(np.sqrt(num_ims))\n","    ncols=int(np.ceil(num_ims/nrows))\n","    print(nrows,ncols)\n","    count=0\n","    if nrows==1 and ncols==1:\n","      print('Label: %s'%label)\n","      plt.imshow(image)\n","      plt.show()\n","    else:\n","      print(labels)\n","      fig = plt.figure(figsize=figsize)\n","      for i in range(nrows):\n","        for j in range(ncols):\n","          if count<num_ims:\n","            fig.add_subplot(nrows,ncols,count+1)\n","            plt.imshow(image[count])\n","            count+=1\n","      fig.set_size_inches(18.5, 10.5)\n","      plt.show()\n","\n","    \n","  def get_misclassified_data(data, labels, predictions):\n","\n","    missed_index     = np.where(np.abs(predictions.squeeze() - labels.squeeze()) > 0)[0]\n","    missed_labels    = labels[missed_index]\n","    missed_data      = data[missed_index,:]\n","    predicted_labels = predictions[missed_index]\n","    return missed_data, missed_labels, predicted_labels, missed_index\n","\n","  def combine_data(data_list, labels_list):\n","    return np.concatenate(data_list, axis = 0), np.concatenate(labels_list, axis = 0)\n","\n","  def model_to_string(model):\n","    import re\n","    stringlist = []\n","    model.summary(print_fn=lambda x: stringlist.append(x))\n","    sms = \"\\n\".join(stringlist)\n","    sms = re.sub('_\\d\\d\\d','', sms)\n","    sms = re.sub('_\\d\\d','', sms)\n","    sms = re.sub('_\\d','', sms)  \n","    return sms\n","\n","  def plot_acc(history, ax = None, xlabel = 'Epoch #'):\n","    history = history.history\n","    history.update({'epoch':list(range(len(history['val_accuracy'])))})\n","    history = pd.DataFrame.from_dict(history)\n","\n","    best_epoch = history.sort_values(by = 'val_accuracy', ascending = False).iloc[0]['epoch']\n","\n","    if not ax:\n","      f, ax = plt.subplots(1,1)\n","    sns.lineplot(x = 'epoch', y = 'val_accuracy', data = history, label = 'Validation', ax = ax)\n","    sns.lineplot(x = 'epoch', y = 'accuracy', data = history, label = 'Training', ax = ax)\n","    ax.axhline(0.25, linestyle = '--',color='red', label = 'Chance')\n","    ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')  \n","    ax.legend(loc = 1)    \n","    ax.set_ylim([0.01, 1])\n","\n","    ax.set_xlabel(xlabel)\n","    ax.set_ylabel('Accuracy (Fraction)')\n","    \n","    plt.show()\n","\n","class models:\n","  def DenseClassifier(hidden_layer_sizes, nn_params, dropout = 0.5):\n","    model = Sequential()\n","    model.add(Flatten(input_shape = nn_params['input_shape']))\n","    for ilayer in hidden_layer_sizes:\n","      model.add(Dense(ilayer, activation = 'relu'))\n","      if dropout:\n","        model.add(Dropout(dropout))\n","    model.add(Dense(units = nn_params['output_neurons'], activation = nn_params['output_activation']))\n","    model.compile(loss=nn_params['loss'],\n","                  optimizer=optimizers.SGD(lr=1e-4, momentum=0.95),\n","                  metrics=['accuracy'])\n","    return model\n","\n","  def CNNClassifier(num_hidden_layers, nn_params, dropout = 0.5):\n","    model = Sequential()\n","\n","    model.add(Conv2D(32, (3, 3), input_shape=nn_params['input_shape'], padding = 'same'))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    for i in range(num_hidden_layers-1):\n","        model.add(Conv2D(32, (3, 3), padding = 'same'))\n","        model.add(Activation('relu'))\n","        model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    model.add(Flatten()) \n","\n","    model.add(Dense(units = 128, activation = 'relu'))\n","    model.add(Dropout(dropout))\n","\n","    model.add(Dense(units = 64, activation = 'relu'))\n","\n","\n","    model.add(Dense(units = nn_params['output_neurons'], activation = nn_params['output_activation']))\n","\n","    # initiate RMSprop optimizer\n","    opt = tensorflow.keras.optimizers.RMSprop(lr=1e-4)\n","\n","    # Let's train the model using RMSprop\n","    model.compile(loss=nn_params['loss'],\n","                  optimizer=opt,\n","                  metrics=['accuracy'])    \n","    return model\n","\n","  def TransferClassifier(name, nn_params):\n","    expert_dict = {'VGG16': VGG16, \n","                   'VGG19': VGG19,\n","                   'ResNet50':ResNet50,\n","                   'DenseNet121':DenseNet121}\n","\n","    expert_conv = expert_dict[name](weights = 'imagenet', \n","                                              include_top = False, \n","                                              input_shape = nn_params['input_shape'])\n","    \n","    expert_model = Sequential()\n","    expert_model.add(expert_conv)\n","    expert_model.add(GlobalAveragePooling2D())\n","\n","    expert_model.add(Dense(1024, activation = 'relu'))\n","    expert_model.add(Dropout(0.3))\n","\n","    expert_model.add(Dense(512, activation = 'relu'))\n","    expert_model.add(Dropout(0.3))\n","\n","    expert_model.add(Dense(nn_params['output_neurons'],\n","                           activation = nn_params['output_activation']))\n","\n","    expert_model.compile(loss = nn_params['loss'], \n","                  optimizer = optimizers.SGD(lr=1e-4, momentum=0.95), \n","                  metrics=['accuracy'])\n","\n","    return expert_model\n","\n","import gdown\n","import zipfile\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","from sklearn import model_selection\n","\n","from collections import Counter\n","\n","import tensorflow.keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Activation, MaxPooling2D, Dropout, Flatten, Reshape, Dense, Conv2D, GlobalAveragePooling2D\n","from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n","import tensorflow.keras.optimizers as optimizers\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","from tensorflow.keras.applications import VGG16, VGG19, ResNet50, DenseNet121\n","\n","from imgaug import augmenters \n","\n","### defining project variables\n","# file variables\n","image_data_url       = 'https://drive.google.com/uc?id=1qmTuUyn0525-612yS-wkp8gHB72Wv_XP'\n","metadata_url         = 'https://drive.google.com/uc?id=1OfKnq3uIT29sXjWSZqOOpceig8Ul24OW'\n","image_data_path      = './image_data.npy'\n","metadata_path        = './metadata.csv'\n","image_shape          = (64, 64, 3)\n","\n","# neural net parameters\n","nn_params = {}\n","nn_params['input_shape']       = image_shape\n","nn_params['output_neurons']    = 4\n","nn_params['loss']              = 'categorical_crossentropy'\n","nn_params['output_activation'] = 'softmax'\n","\n","###\n","gdown.download(image_data_url, image_data_path , True)\n","gdown.download(metadata_url, metadata_path , True)\n","\n","\n","### pre-loading all data of interest\n","_all_data = np.load('image_data.npy')\n","_metadata = pkg.get_metadata(metadata_path, ['train','test','field'])\n","\n","### preparing definitions\n","# downloading and loading data\n","get_data_split = pkg.get_data_split\n","get_metadata    = lambda :                 pkg.get_metadata(metadata_path, ['train','test'])\n","get_train_data  = lambda flatten = False : pkg.get_train_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n","get_test_data   = lambda flatten = False : pkg.get_test_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n","get_field_data  = lambda flatten = False : pkg.get_field_data(flatten = flatten, all_data = _all_data, metadata = _metadata, image_shape = image_shape)\n","\n","# plotting\n","plot_image = lambda data, num_ims,figsize=(8,6), labels = [], index = None: helpers.plot_image(data = data, num_ims=num_ims, figsize=figsize,labels = labels, index = index, image_shape = image_shape);\n","plot_acc       = lambda history: helpers.plot_acc(history)\n","\n","# querying and combining data\n","model_to_string        = lambda model: helpers.model_to_string(model)\n","get_misclassified_data = helpers.get_misclassified_data;\n","combine_data           = helpers.combine_data;\n","\n","# models with input parameters\n","DenseClassifier     = lambda hidden_layer_sizes: models.DenseClassifier(hidden_layer_sizes = hidden_layer_sizes, nn_params = nn_params);\n","CNNClassifier       = lambda num_hidden_layers: models.CNNClassifier(num_hidden_layers, nn_params = nn_params);\n","TransferClassifier  = lambda name: models.TransferClassifier(name = name, nn_params = nn_params);\n","\n","monitor = ModelCheckpoint('./model.h5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"cqFAnQCxsgRm","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592340005109,"user_tz":420,"elapsed":646,"user":{"displayName":"Shafin Haque","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdwtEd_daS6_Iby03E8_oqJRD1DxQTM7iYf1dWzg=s64","userId":"00476594546562972086"}}},"source":["# grab tools from our tensorflow and keras toolboxes!\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n","from tensorflow.keras import optimizers"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cPOqTta1sb6e","colab_type":"text"},"source":["Before we train the model or use it to predict something, we have to **create** the model. "]},{"cell_type":"code","metadata":{"id":"Yus22AQpsqMH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592340018032,"user_tz":420,"elapsed":8997,"user":{"displayName":"Shafin Haque","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdwtEd_daS6_Iby03E8_oqJRD1DxQTM7iYf1dWzg=s64","userId":"00476594546562972086"}}},"source":["# create our model by specifying and compiling it\n","model = Sequential()\n","model.add(Dense(4, input_shape=(3,),activation = 'relu'))\n","model.add(Dense(1, activation = 'linear'))\n","model.compile(loss='mean_squared_error',\n","                optimizer='adam',\n","                metrics=['mean_squared_error'])"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"vNDBeK9K2ZzU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592343546930,"user_tz":420,"elapsed":944,"user":{"displayName":"Shafin Haque","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdwtEd_daS6_Iby03E8_oqJRD1DxQTM7iYf1dWzg=s64","userId":"00476594546562972086"}}},"source":["cnn = Sequential()\n","cnn.add(Conv2D(64, (3, 3), input_shape=(64, 64, 3)))\n","cnn.add(Activation('relu'))\n","cnn.add(MaxPooling2D(pool_size=(2, 2)))\n","cnn.add(Flatten()) \n","cnn.add(Dense(units = 128, activation = 'relu'))\n","cnn.add(Dense(units = 4, activation = 'softmax'))\n","\n","# compile the network \n","cnn.compile(loss='categorical_crossentropy', optimizer = optimizers.SGD(lr=1e-3, momentum=0.95), metrics = ['accuracy'])\n","### END CODE"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s858q9Nd4vk-","colab_type":"text"},"source":["Once we've compiled the network, train it for 100 epochs. \n","Remember how you did this for the MLP (`model_2`)?\n","\n"]},{"cell_type":"code","metadata":{"id":"_HTn3r594KWZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592344022861,"user_tz":420,"elapsed":158739,"user":{"displayName":"Shafin Haque","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdwtEd_daS6_Iby03E8_oqJRD1DxQTM7iYf1dWzg=s64","userId":"00476594546562972086"}},"outputId":"f26eb198-7694-4760-c692-62d8b3f44640"},"source":["### YOUR CODE HERE\n","history = cnn.fit(train_data, train_labels, epochs = 100, validation_data = (test_data, test_labels), shuffle = True, callbacks = [monitor])\n","### END CODE"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","211/211 [==============================] - 2s 8ms/step - loss: 3.2156e-04 - accuracy: 1.0000 - val_loss: 6.4595 - val_accuracy: 0.3457\n","Epoch 2/100\n","211/211 [==============================] - 2s 8ms/step - loss: 3.2312e-04 - accuracy: 1.0000 - val_loss: 6.5746 - val_accuracy: 0.3380\n","Epoch 3/100\n","211/211 [==============================] - 2s 8ms/step - loss: 3.1117e-04 - accuracy: 1.0000 - val_loss: 6.7909 - val_accuracy: 0.3370\n","Epoch 4/100\n","211/211 [==============================] - 2s 8ms/step - loss: 3.1431e-04 - accuracy: 1.0000 - val_loss: 6.7014 - val_accuracy: 0.3370\n","Epoch 5/100\n","211/211 [==============================] - 2s 7ms/step - loss: 3.0600e-04 - accuracy: 1.0000 - val_loss: 6.7086 - val_accuracy: 0.3370\n","Epoch 6/100\n","211/211 [==============================] - 2s 7ms/step - loss: 2.9736e-04 - accuracy: 1.0000 - val_loss: 6.5415 - val_accuracy: 0.3424\n","Epoch 7/100\n","211/211 [==============================] - 2s 7ms/step - loss: 2.9245e-04 - accuracy: 1.0000 - val_loss: 6.7769 - val_accuracy: 0.3391\n","Epoch 8/100\n","211/211 [==============================] - 2s 7ms/step - loss: 2.8765e-04 - accuracy: 1.0000 - val_loss: 6.6608 - val_accuracy: 0.3413\n","Epoch 9/100\n","211/211 [==============================] - 2s 7ms/step - loss: 2.8434e-04 - accuracy: 1.0000 - val_loss: 6.5679 - val_accuracy: 0.3424\n","Epoch 10/100\n","211/211 [==============================] - 2s 7ms/step - loss: 2.7879e-04 - accuracy: 1.0000 - val_loss: 6.7882 - val_accuracy: 0.3348\n","Epoch 11/100\n","211/211 [==============================] - 2s 7ms/step - loss: 2.7049e-04 - accuracy: 1.0000 - val_loss: 6.7064 - val_accuracy: 0.3380\n","Epoch 12/100\n","211/211 [==============================] - 2s 7ms/step - loss: 2.6628e-04 - accuracy: 1.0000 - val_loss: 6.9004 - val_accuracy: 0.3380\n","Epoch 13/100\n","211/211 [==============================] - 2s 8ms/step - loss: 2.6018e-04 - accuracy: 1.0000 - val_loss: 6.5595 - val_accuracy: 0.3457\n","Epoch 14/100\n","211/211 [==============================] - 2s 8ms/step - loss: 2.6474e-04 - accuracy: 1.0000 - val_loss: 6.8072 - val_accuracy: 0.3370\n","Epoch 15/100\n","211/211 [==============================] - 2s 7ms/step - loss: 2.5428e-04 - accuracy: 1.0000 - val_loss: 6.9205 - val_accuracy: 0.3380\n","Epoch 16/100\n","211/211 [==============================] - 2s 7ms/step - loss: 2.5463e-04 - accuracy: 1.0000 - val_loss: 6.8581 - val_accuracy: 0.3380\n","Epoch 17/100\n","211/211 [==============================] - 2s 7ms/step - loss: 2.4563e-04 - accuracy: 1.0000 - val_loss: 6.8256 - val_accuracy: 0.3359\n","Epoch 18/100\n","211/211 [==============================] - 2s 7ms/step - loss: 2.4133e-04 - accuracy: 1.0000 - val_loss: 6.7602 - val_accuracy: 0.3391\n","Epoch 19/100\n","211/211 [==============================] - 2s 7ms/step - loss: 2.4026e-04 - accuracy: 1.0000 - val_loss: 6.8447 - val_accuracy: 0.3370\n","Epoch 20/100\n","211/211 [==============================] - 2s 7ms/step - loss: 2.3659e-04 - accuracy: 1.0000 - val_loss: 6.8732 - val_accuracy: 0.3391\n","Epoch 21/100\n","211/211 [==============================] - 2s 7ms/step - loss: 2.3609e-04 - accuracy: 1.0000 - val_loss: 6.7957 - val_accuracy: 0.3402\n","Epoch 22/100\n","211/211 [==============================] - 2s 7ms/step - loss: 2.2727e-04 - accuracy: 1.0000 - val_loss: 6.9425 - val_accuracy: 0.3424\n","Epoch 23/100\n","211/211 [==============================] - 2s 7ms/step - loss: 2.2406e-04 - accuracy: 1.0000 - val_loss: 6.7616 - val_accuracy: 0.3413\n","Epoch 24/100\n","211/211 [==============================] - 2s 8ms/step - loss: 2.1987e-04 - accuracy: 1.0000 - val_loss: 6.9622 - val_accuracy: 0.3391\n","Epoch 25/100\n","211/211 [==============================] - 2s 7ms/step - loss: 2.1957e-04 - accuracy: 1.0000 - val_loss: 6.8162 - val_accuracy: 0.3402\n","Epoch 26/100\n","211/211 [==============================] - 2s 7ms/step - loss: 2.1678e-04 - accuracy: 1.0000 - val_loss: 6.9608 - val_accuracy: 0.3402\n","Epoch 27/100\n","211/211 [==============================] - 2s 7ms/step - loss: 2.1766e-04 - accuracy: 1.0000 - val_loss: 6.9287 - val_accuracy: 0.3370\n","Epoch 28/100\n","211/211 [==============================] - 2s 7ms/step - loss: 2.1006e-04 - accuracy: 1.0000 - val_loss: 6.8435 - val_accuracy: 0.3413\n","Epoch 29/100\n","211/211 [==============================] - 2s 7ms/step - loss: 2.0815e-04 - accuracy: 1.0000 - val_loss: 7.0599 - val_accuracy: 0.3380\n","Epoch 30/100\n","211/211 [==============================] - 2s 7ms/step - loss: 2.0538e-04 - accuracy: 1.0000 - val_loss: 7.0583 - val_accuracy: 0.3391\n","Epoch 31/100\n","211/211 [==============================] - 2s 7ms/step - loss: 2.0026e-04 - accuracy: 1.0000 - val_loss: 7.0030 - val_accuracy: 0.3402\n","Epoch 32/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.9921e-04 - accuracy: 1.0000 - val_loss: 6.9316 - val_accuracy: 0.3457\n","Epoch 33/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.9634e-04 - accuracy: 1.0000 - val_loss: 6.9121 - val_accuracy: 0.3424\n","Epoch 34/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.9397e-04 - accuracy: 1.0000 - val_loss: 6.8831 - val_accuracy: 0.3435\n","Epoch 35/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.9207e-04 - accuracy: 1.0000 - val_loss: 6.9647 - val_accuracy: 0.3413\n","Epoch 36/100\n","211/211 [==============================] - 2s 8ms/step - loss: 1.8869e-04 - accuracy: 1.0000 - val_loss: 7.0723 - val_accuracy: 0.3370\n","Epoch 37/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.8761e-04 - accuracy: 1.0000 - val_loss: 6.9557 - val_accuracy: 0.3413\n","Epoch 38/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.8370e-04 - accuracy: 1.0000 - val_loss: 7.0855 - val_accuracy: 0.3380\n","Epoch 39/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.8139e-04 - accuracy: 1.0000 - val_loss: 6.9791 - val_accuracy: 0.3413\n","Epoch 40/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.8329e-04 - accuracy: 1.0000 - val_loss: 7.1203 - val_accuracy: 0.3435\n","Epoch 41/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.7565e-04 - accuracy: 1.0000 - val_loss: 6.9829 - val_accuracy: 0.3446\n","Epoch 42/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.7356e-04 - accuracy: 1.0000 - val_loss: 6.8705 - val_accuracy: 0.3435\n","Epoch 43/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.7649e-04 - accuracy: 1.0000 - val_loss: 7.0419 - val_accuracy: 0.3413\n","Epoch 44/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.6982e-04 - accuracy: 1.0000 - val_loss: 7.1007 - val_accuracy: 0.3391\n","Epoch 45/100\n","211/211 [==============================] - 2s 8ms/step - loss: 1.6641e-04 - accuracy: 1.0000 - val_loss: 6.9122 - val_accuracy: 0.3467\n","Epoch 46/100\n","211/211 [==============================] - 2s 8ms/step - loss: 1.6677e-04 - accuracy: 1.0000 - val_loss: 7.1867 - val_accuracy: 0.3380\n","Epoch 47/100\n","211/211 [==============================] - 2s 8ms/step - loss: 1.6485e-04 - accuracy: 1.0000 - val_loss: 7.1792 - val_accuracy: 0.3359\n","Epoch 48/100\n","211/211 [==============================] - 2s 8ms/step - loss: 1.6438e-04 - accuracy: 1.0000 - val_loss: 7.1219 - val_accuracy: 0.3391\n","Epoch 49/100\n","211/211 [==============================] - 2s 8ms/step - loss: 1.6131e-04 - accuracy: 1.0000 - val_loss: 7.0261 - val_accuracy: 0.3413\n","Epoch 50/100\n","211/211 [==============================] - 2s 8ms/step - loss: 1.6175e-04 - accuracy: 1.0000 - val_loss: 7.1416 - val_accuracy: 0.3380\n","Epoch 51/100\n","211/211 [==============================] - 2s 8ms/step - loss: 1.5871e-04 - accuracy: 1.0000 - val_loss: 7.0348 - val_accuracy: 0.3446\n","Epoch 52/100\n","211/211 [==============================] - 2s 8ms/step - loss: 1.5729e-04 - accuracy: 1.0000 - val_loss: 7.1560 - val_accuracy: 0.3402\n","Epoch 53/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.5354e-04 - accuracy: 1.0000 - val_loss: 7.0518 - val_accuracy: 0.3478\n","Epoch 54/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.5290e-04 - accuracy: 1.0000 - val_loss: 7.2605 - val_accuracy: 0.3370\n","Epoch 55/100\n","211/211 [==============================] - 2s 8ms/step - loss: 1.5112e-04 - accuracy: 1.0000 - val_loss: 7.3287 - val_accuracy: 0.3348\n","Epoch 56/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.5135e-04 - accuracy: 1.0000 - val_loss: 7.2158 - val_accuracy: 0.3424\n","Epoch 57/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.4936e-04 - accuracy: 1.0000 - val_loss: 7.1412 - val_accuracy: 0.3435\n","Epoch 58/100\n","211/211 [==============================] - 2s 8ms/step - loss: 1.4816e-04 - accuracy: 1.0000 - val_loss: 7.1851 - val_accuracy: 0.3435\n","Epoch 59/100\n","211/211 [==============================] - 2s 8ms/step - loss: 1.4542e-04 - accuracy: 1.0000 - val_loss: 7.1860 - val_accuracy: 0.3391\n","Epoch 60/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.4452e-04 - accuracy: 1.0000 - val_loss: 7.2266 - val_accuracy: 0.3391\n","Epoch 61/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.4275e-04 - accuracy: 1.0000 - val_loss: 7.1088 - val_accuracy: 0.3446\n","Epoch 62/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.4095e-04 - accuracy: 1.0000 - val_loss: 7.2344 - val_accuracy: 0.3413\n","Epoch 63/100\n","211/211 [==============================] - 2s 8ms/step - loss: 1.4071e-04 - accuracy: 1.0000 - val_loss: 7.3581 - val_accuracy: 0.3380\n","Epoch 64/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.3951e-04 - accuracy: 1.0000 - val_loss: 7.1348 - val_accuracy: 0.3446\n","Epoch 65/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.3874e-04 - accuracy: 1.0000 - val_loss: 7.2206 - val_accuracy: 0.3446\n","Epoch 66/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.3798e-04 - accuracy: 1.0000 - val_loss: 7.2723 - val_accuracy: 0.3413\n","Epoch 67/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.3913e-04 - accuracy: 1.0000 - val_loss: 7.1546 - val_accuracy: 0.3446\n","Epoch 68/100\n","211/211 [==============================] - 2s 8ms/step - loss: 1.3374e-04 - accuracy: 1.0000 - val_loss: 7.1909 - val_accuracy: 0.3402\n","Epoch 69/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.3319e-04 - accuracy: 1.0000 - val_loss: 7.1578 - val_accuracy: 0.3424\n","Epoch 70/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.2957e-04 - accuracy: 1.0000 - val_loss: 7.2318 - val_accuracy: 0.3402\n","Epoch 71/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.3034e-04 - accuracy: 1.0000 - val_loss: 7.2687 - val_accuracy: 0.3413\n","Epoch 72/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.2889e-04 - accuracy: 1.0000 - val_loss: 7.2745 - val_accuracy: 0.3402\n","Epoch 73/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.2721e-04 - accuracy: 1.0000 - val_loss: 7.2952 - val_accuracy: 0.3402\n","Epoch 74/100\n","211/211 [==============================] - 2s 8ms/step - loss: 1.2681e-04 - accuracy: 1.0000 - val_loss: 7.1654 - val_accuracy: 0.3435\n","Epoch 75/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.2465e-04 - accuracy: 1.0000 - val_loss: 7.2913 - val_accuracy: 0.3413\n","Epoch 76/100\n","211/211 [==============================] - 2s 8ms/step - loss: 1.2395e-04 - accuracy: 1.0000 - val_loss: 7.3185 - val_accuracy: 0.3402\n","Epoch 77/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.2378e-04 - accuracy: 1.0000 - val_loss: 7.3442 - val_accuracy: 0.3402\n","Epoch 78/100\n","211/211 [==============================] - 2s 8ms/step - loss: 1.2277e-04 - accuracy: 1.0000 - val_loss: 7.3365 - val_accuracy: 0.3435\n","Epoch 79/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.2086e-04 - accuracy: 1.0000 - val_loss: 7.3768 - val_accuracy: 0.3380\n","Epoch 80/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.1801e-04 - accuracy: 1.0000 - val_loss: 7.3614 - val_accuracy: 0.3413\n","Epoch 81/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.2026e-04 - accuracy: 1.0000 - val_loss: 7.3755 - val_accuracy: 0.3402\n","Epoch 82/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.1721e-04 - accuracy: 1.0000 - val_loss: 7.2740 - val_accuracy: 0.3435\n","Epoch 83/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.1699e-04 - accuracy: 1.0000 - val_loss: 7.4483 - val_accuracy: 0.3402\n","Epoch 84/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.1605e-04 - accuracy: 1.0000 - val_loss: 7.2980 - val_accuracy: 0.3446\n","Epoch 85/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.1461e-04 - accuracy: 1.0000 - val_loss: 7.4926 - val_accuracy: 0.3413\n","Epoch 86/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.1376e-04 - accuracy: 1.0000 - val_loss: 7.3671 - val_accuracy: 0.3391\n","Epoch 87/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.1314e-04 - accuracy: 1.0000 - val_loss: 7.4763 - val_accuracy: 0.3391\n","Epoch 88/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.1204e-04 - accuracy: 1.0000 - val_loss: 7.4401 - val_accuracy: 0.3402\n","Epoch 89/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.0990e-04 - accuracy: 1.0000 - val_loss: 7.6241 - val_accuracy: 0.3391\n","Epoch 90/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.1097e-04 - accuracy: 1.0000 - val_loss: 7.2840 - val_accuracy: 0.3435\n","Epoch 91/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.0922e-04 - accuracy: 1.0000 - val_loss: 7.5246 - val_accuracy: 0.3402\n","Epoch 92/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.0796e-04 - accuracy: 1.0000 - val_loss: 7.5011 - val_accuracy: 0.3402\n","Epoch 93/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.0843e-04 - accuracy: 1.0000 - val_loss: 7.4887 - val_accuracy: 0.3391\n","Epoch 94/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.0652e-04 - accuracy: 1.0000 - val_loss: 7.3608 - val_accuracy: 0.3435\n","Epoch 95/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.0735e-04 - accuracy: 1.0000 - val_loss: 7.4502 - val_accuracy: 0.3424\n","Epoch 96/100\n","211/211 [==============================] - 2s 8ms/step - loss: 1.0591e-04 - accuracy: 1.0000 - val_loss: 7.5117 - val_accuracy: 0.3424\n","Epoch 97/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.0385e-04 - accuracy: 1.0000 - val_loss: 7.5860 - val_accuracy: 0.3380\n","Epoch 98/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.0385e-04 - accuracy: 1.0000 - val_loss: 7.5079 - val_accuracy: 0.3391\n","Epoch 99/100\n","211/211 [==============================] - 2s 7ms/step - loss: 1.0349e-04 - accuracy: 1.0000 - val_loss: 7.3216 - val_accuracy: 0.3424\n","Epoch 100/100\n","211/211 [==============================] - 2s 8ms/step - loss: 1.0236e-04 - accuracy: 1.0000 - val_loss: 7.6042 - val_accuracy: 0.3380\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0VB79BCx7tvg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":693},"executionInfo":{"status":"error","timestamp":1592344719257,"user_tz":420,"elapsed":109217,"user":{"displayName":"Shafin Haque","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdwtEd_daS6_Iby03E8_oqJRD1DxQTM7iYf1dWzg=s64","userId":"00476594546562972086"}},"outputId":"bc35e03b-84d8-49bd-ac65-ee8f7a954ad0"},"source":["# As always, we get our data first\n","train_data, train_labels = get_train_data(flatten=True)\n","test_data, test_labels = get_test_data(flatten=True)\n","\n","train_data = train_data.reshape([-1, 64, 64, 3])\n","test_data = test_data.reshape([-1, 64, 64, 3])\n","\n","train_labels = label_to_numpy(train_labels)\n","test_labels = label_to_numpy(test_labels)\n","\n","### YOUR CODE HERE\n","transfer = TransferClassifier('DenseNet121')\n","\n","history = transfer.fit(train_data, train_labels, epochs = 100, validation_data = (test_data, test_labels), shuffle = True, callbacks = [monitor])\n","plot_acc(history)\n","\n","### END CODE"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","211/211 [==============================] - 12s 58ms/step - loss: 1.0000 - accuracy: 0.5980 - val_loss: 1.1402 - val_accuracy: 0.4783\n","Epoch 2/100\n","211/211 [==============================] - 11s 52ms/step - loss: 0.2247 - accuracy: 0.9346 - val_loss: 1.0039 - val_accuracy: 0.5783\n","Epoch 3/100\n","211/211 [==============================] - 11s 51ms/step - loss: 0.0839 - accuracy: 0.9798 - val_loss: 0.9877 - val_accuracy: 0.6293\n","Epoch 4/100\n","211/211 [==============================] - 10s 49ms/step - loss: 0.0473 - accuracy: 0.9903 - val_loss: 1.0008 - val_accuracy: 0.6283\n","Epoch 5/100\n","211/211 [==============================] - 11s 52ms/step - loss: 0.0309 - accuracy: 0.9926 - val_loss: 0.9620 - val_accuracy: 0.6424\n","Epoch 6/100\n","211/211 [==============================] - 10s 49ms/step - loss: 0.0220 - accuracy: 0.9955 - val_loss: 1.0254 - val_accuracy: 0.6272\n","Epoch 7/100\n","211/211 [==============================] - 10s 48ms/step - loss: 0.0191 - accuracy: 0.9967 - val_loss: 0.9855 - val_accuracy: 0.6424\n","Epoch 8/100\n","211/211 [==============================] - 10s 48ms/step - loss: 0.0150 - accuracy: 0.9979 - val_loss: 1.0381 - val_accuracy: 0.6326\n","Epoch 9/100\n"," 51/211 [======>.......................] - ETA: 7s - loss: 0.0163 - accuracy: 0.9982"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-214b42542d4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtransfer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransferClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DenseNet121'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mplot_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}